[
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "My name is Hayley Hemme and I’m a second-year master of public health student concentrating in epidemiology. I received my bachelor of science in Biology from Brenau University in 2017 where I concentrated in biomedical sciences. I have previous training as an HIV tester and counselor, and worked in the emergency department as a medical scribe and clinical technician before returning to school to pursue my masters.\nMy primary interest is in infectious disease epidemiology, specifically HIV. An area of research I am interested in is the use of molecular HIV surveillance to detect clusters, and how these methods might be used with conjunction with spatial methods to predict future clusters and help better inform resource allocation.\nI have taken multiple courses that utilize statistics, programming, and/or data analysis, including all the required core classes for my program, as well as Spatial Epidemiology and Introduction to Coding in R. I experience working with STATA, SAS, and R, and while I am most comfortable working in R, I know there is still a lot for me to learn! What I hope to get most out of this course is functional knowledge of variety of data analysis methods and to improve on communicating results to stakeholders from a variety of backgrounds.\n\nAn interesting fact about me\n\nI am an intermediate-level aerialist training on trapeze and aerial sling.\nI am exotic pet hobbyist with a fear of “bugs” and arachnids, despite having several in my collection.\nI enjoy doing tricks training with my dog, Punch.\n\n\n\n\nMe and my dog Punch at Boo-le-bark.\n\n\n\n\nMyth: The Data Speaks for Itself\nThe link above is to a post on blog that was recently shared with me. I appreciate the author’s insight to data reporting, however blunt they may be. This particular post speaks to the perceived objectivity of data. I think that it’s important to understand that data may be interpreted in different ways, even among those with data literacy. She advocates that data story-telling be presented alongside results of data in order to better explain real-world implications."
  },
  {
    "objectID": "coding_exercise.html",
    "href": "coding_exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Loading packages\nLoading data\nSubsetting data from African countries\nCreating new objects from ‘africadata’– ‘imle’ containing infant mortality and life expectancy, and ‘ple’ containing population size and life expectancy\nData Visualization\nNext, let’s find out which years are missing data on infant mortality\nSubsetting data from the year 2000\nPlotting data from African Countries in 2000\nFitting a simple model\nConclusions\nThere is statistically significant evidence supporting an association between life expectancy and infant mortality. Life expectancy decreases by 2.49 years for every unit increase in infant mortality (p < 0.05). The data does not show statistically significant evidence of association between life expectancy and population size (p = 0.62)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hayley Hemme’s Website and Data Analysis Portfolio",
    "section": "",
    "text": "Hello!\n\nWelcome to my website and data analysis portfolio.\nPlease check back throughout the Spring 2023 semester to stay up to date with my progress in the MADA course.\n\nPlease use the Menu Bar above to look around.\nThank you!"
  },
  {
    "objectID": "tidytuesday_exercise.html",
    "href": "tidytuesday_exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "library(here)\nlibrary(epiDisplay)\nlibrary(tidyverse)\nlibrary(plotly)\n\nThis data was obtained from the github Importing the data\n\nage_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')\n\nwrite_csv(age_gaps, here(\"data/age_gaps.csv\"))\n\nLet’s start by taking a glimpse at the dataset.\n\nglimpse(age_gaps)\n\nRows: 1,155\nColumns: 13\n$ movie_name         <chr> \"Harold and Maude\", \"Venus\", \"The Quiet American\", …\n$ release_year       <dbl> 1971, 2006, 2002, 1998, 2010, 1992, 2009, 1999, 199…\n$ director           <chr> \"Hal Ashby\", \"Roger Michell\", \"Phillip Noyce\", \"Joe…\n$ age_difference     <dbl> 52, 50, 49, 45, 43, 42, 40, 39, 38, 38, 36, 36, 35,…\n$ couple_number      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ actor_1_name       <chr> \"Ruth Gordon\", \"Peter O'Toole\", \"Michael Caine\", \"D…\n$ actor_2_name       <chr> \"Bud Cort\", \"Jodie Whittaker\", \"Do Thi Hai Yen\", \"T…\n$ character_1_gender <chr> \"woman\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", …\n$ character_2_gender <chr> \"man\", \"woman\", \"woman\", \"woman\", \"man\", \"woman\", \"…\n$ actor_1_birthdate  <date> 1896-10-30, 1932-08-02, 1933-03-14, 1930-09-17, 19…\n$ actor_2_birthdate  <date> 1948-03-29, 1982-06-03, 1982-10-01, 1975-11-08, 19…\n$ actor_1_age        <dbl> 75, 74, 69, 68, 81, 59, 62, 69, 57, 77, 59, 56, 65,…\n$ actor_2_age        <dbl> 23, 24, 20, 23, 38, 17, 22, 30, 19, 39, 23, 20, 30,…\n\n\nLet’s take a look at some summary statistics on age_difference.\n\nage_gaps %>% pull(age_difference) %>% summary()\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    4.00    8.00   10.42   15.00   52.00 \n\n\nLet’s see how many unique movies are included in the dataset.\n\nage_gaps %>% pull(movie_name) %>% n_distinct()\n\n[1] 830\n\n\nThere are 830 unique movies.\nLet’s also look at how many different directors appear in the dataset.\n\nage_gaps %>% pull(director) %>% n_distinct()\n\n[1] 510\n\n\nThere are 510 unique directors.\nLet’s make a new variable for th the number of movies released each decade in the dataset. We’ll do this by performing integer division using %/% and multiplying by 10.\n\nage_gaps <- age_gaps %>% \n  mutate(decade_released = 10 * (release_year %/% 10))\n\n\nage_gaps %>% \n  count(decade_released) %>% \n  ggplot() + geom_line(aes(decade_released, n)) +\n  scale_x_continuous(breaks = seq(1930,2020, 10))\n\n\n\n\nWe can see that the decade with the most movie releases was 2000.\nLet’s create variable for the largest age difference by decade released.\n\nage_gaps <- age_gaps %>%\n  group_by(decade_released) %>% \n  mutate(max_age_diff = max(age_difference))\n\nage_gaps %>% \n   ggplot() + \n  geom_line(data = age_gaps, aes(x = decade_released, y= max_age_diff))  + \n  scale_x_continuous(breaks = seq(1930,2020, 10))\n\n\n\n\nLet’s see if we can combine these plots and add some design elements.\n\nplot <- age_gaps %>% \n  count(decade_released) %>% \n  ggplot() + geom_line(aes(decade_released, n), color = \"red\", linewidth = 1) +\n    geom_line(data = age_gaps, aes(x = decade_released, y= max_age_diff),\n              color = \"pink\" , linewidth = 1)  +\n  scale_x_continuous(breaks = seq(1930,2020, 10)) + \n  labs(x = \"Year of Movie Release\", y = \"Number of Movies Released\",\n       title = \"Number of Movies Released with Love Interests and Largest Age Gap,\n       by Decade\") +\n  theme_classic()\n\nplot \n\n\n\n\nLet’s make the plot interactive!\n\nremove_buttons <- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\nggplotly(plot) %>% config(modeBarButtonsToRemove = remove_buttons)  \n\n\n\n\n\nNext, let’s switch gears entirely and find out what the most common name is among directors. We’ll need to load tidytext().\n\nlibrary(tidytext)\n\nage_gaps %>% ungroup() %>%\n  distinct(director) %>% \n  unnest_tokens(word, director) %>% \n  count(word, sort = TRUE) %>% \n  top_n(15)\n\n# A tibble: 15 × 2\n   word        n\n   <chr>   <int>\n 1 john       17\n 2 david      14\n 3 michael    13\n 4 peter      12\n 5 paul       11\n 6 george     10\n 7 james      10\n 8 robert     10\n 9 richard     7\n10 jon         6\n11 kevin       6\n12 lee         6\n13 mark        6\n14 scott       6\n15 steven      6\n\n\nLet’s see what the most common names are among directors with a ‘large’ age difference. Let’s use observations with an age difference >= 15 years, which is >= 75th quantile.\n\nage_gaps %>% pull(age_difference) %>% quantile()\n\n  0%  25%  50%  75% 100% \n   0    4    8   15   52 \n\nage_gaps %>% ungroup() %>%\n  filter(age_difference >= 15) %>% \n  distinct(director) %>% \n  unnest_tokens(word, director) %>% \n  count(word, sort = TRUE) %>%\n  top_n(15)\n\nSelecting by n\n\n\n# A tibble: 16 × 2\n   word        n\n   <chr>   <int>\n 1 john        8\n 2 david       6\n 3 michael     5\n 4 peter       5\n 5 marc        4\n 6 paul        4\n 7 richard     4\n 8 robert      4\n 9 scott       4\n10 george      3\n11 james       3\n12 joseph      3\n13 lee         3\n14 mike        3\n15 steven      3\n16 thomas      3\n\n\nWhile the top 5 directors are identical to the previous list, Marc appears in the 6th most frequent among directors of movies with an age difference greater than or equal to 15 years.\nLet’s find out which movies these Marc’s directed.\n\nage_gaps %>%\n   filter(grepl(\"Marc \", director)) %>%\n   arrange(desc(release_year))\n\n# A tibble: 14 × 15\n# Groups:   decade_released [2]\n   movie_name    relea…¹ direc…² age_d…³ coupl…⁴ actor…⁵ actor…⁶ chara…⁷ chara…⁸\n   <chr>           <dbl> <chr>     <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>  \n 1 The Only Liv…    2017 Marc W…      20       1 Pierce… Kate B… man     woman  \n 2 All I See Is…    2017 Marc F…      18       1 Jason … Blake … man     woman  \n 3 The Only Liv…    2017 Marc W…      17       2 Kate B… Callum… woman   man    \n 4 The Only Liv…    2017 Marc W…       3       3 Callum… Kierse… man     woman  \n 5 World War Z      2013 Marc F…      12       1 Brad P… Mireil… man     woman  \n 6 The Amazing …    2012 Marc W…       5       1 Andrew… Emma S… man     woman  \n 7 The Young Vi…    2009 Jean-M…       2       1 Rupert… Emily … man     woman  \n 8 500 Days of …    2009 Marc W…       1       1 Zooey … Joseph… woman   man    \n 9 Quantum of S…    2008 Marc F…      18       1 Daniel… Gemma … man     woman  \n10 Suburban Girl    2007 Marc K…      19       1 Alec B… Sarah … man     woman  \n11 Music and Ly…    2007 Marc L…      15       1 Hugh G… Drew B… man     woman  \n12 Stranger Tha…    2006 Marc F…      10       1 Will F… Maggie… man     woman  \n13 Two Weeks No…    2002 Marc L…       4       1 Hugh G… Sandra… man     woman  \n14 Monster's Ba…    2001 Marc F…      11       1 Billy … Halle … man     woman  \n# … with 6 more variables: actor_1_birthdate <date>, actor_2_birthdate <date>,\n#   actor_1_age <dbl>, actor_2_age <dbl>, decade_released <dbl>,\n#   max_age_diff <dbl>, and abbreviated variable names ¹​release_year,\n#   ²​director, ³​age_difference, ⁴​couple_number, ⁵​actor_1_name, ⁶​actor_2_name,\n#   ⁷​character_1_gender, ⁸​character_2_gender\n\n\nSo, it looks like our filter picked up a sneaky Marc… Jean-Marc. Let’s remove this observation by specifying that the director’s name must begin with Marc.\n\nmarc <- age_gaps %>%\n  filter(grepl(\"^Marc \", director))\n\nmarc %>%\n  pull(movie_name) %>%\n  unique()\n\n [1] \"The Only Living Boy in New York\" \"Suburban Girl\"                  \n [3] \"All I See Is You\"                \"Quantum of Solace\"              \n [5] \"Music and Lyrics\"                \"World War Z\"                    \n [7] \"Monster's Ball\"                  \"Stranger Than Fiction\"          \n [9] \"The Amazing Spider-Man\"          \"Two Weeks Notice\"               \n[11] \"500 Days of Summer\"             \n\n\nLet’s find the average age difference for these Marc-directed love movies\n\nmarc %>%\n  pull(age_difference) %>%\n  summary()\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    5.00   12.00   11.77   18.00   20.00 \n\n\n\nmarc %>%\n  pull(director) %>%\n  unique()\n\n[1] \"Marc Webb\"     \"Marc Klein\"    \"Marc Forster\"  \"Marc Lawrence\"\n\n\nLet’s also rename the director variable and drop Marc from the rows using str_replace.\n\nlibrary(stringr)\n\nmarc$director <- str_replace(marc$director, \"Marc \", \"\")\n\nmarc <- marc %>% rename(`Director Marc` = director)\n\n\nmarc %>% ggplot(aes(x= release_year, y= age_difference, color= `Director Marc`)) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = seq(2001, 2019, 3)) +\n  labs(x = \"Year of Movie Release\", y = \"Age Difference in Years\",\n       title = \"Age Gaps in Movies by Marc(s) by Year Released\")\n\n\n\n\nWhile my approach to this exercise was obviously silly, I learned a lot about the tidytext package, which I’d never used before, and a useful trick for a function I use regularly!\n\nwrite_csv(age_gaps, here(\"data/age_gaps_edited.csv\"))"
  },
  {
    "objectID": "visualization_exercise.html",
    "href": "visualization_exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\nhere()\n\n[1] \"C:/Users/Hayley/Desktop/MADA2023/hayleyhemme-MADA-portfolio\"\n\n\nThe plot we’ll be trying to replicate is from Our World in Data.\n\n\n\n\n\n\nHIV_GBD <- read_csv(here(\"data/deaths-from-hiv-by-age.csv\"))\nglimpse(HIV_GBD)\n\nRows: 6,840\nColumns: 8\n$ Entity                                                      <chr> \"Afghanist…\n$ Code                                                        <chr> \"AFG\", \"AF…\n$ Year                                                        <dbl> 1990, 1991…\n$ `Deaths - HIV/AIDS - Sex: Both - Age: 70+ years (Number)`   <dbl> 1, 1, 2, 2…\n$ `Deaths - HIV/AIDS - Sex: Both - Age: 50-69 years (Number)` <dbl> 7, 8, 9, 1…\n$ `Deaths - HIV/AIDS - Sex: Both - Age: 15-49 years (Number)` <dbl> 15, 19, 24…\n$ `Deaths - HIV/AIDS - Sex: Both - Age: 5-14 years (Number)`  <dbl> 0, 0, 0, 1…\n$ `Deaths - HIV/AIDS - Sex: Both - Age: Under 5 (Number)`     <dbl> 10, 12, 13…\n\n\nLet’s group by year and find the sum of deaths for each year in each age group.\n\nyear_sums_70 <- HIV_GBD %>% group_by(Year) %>% \n  summarize(`70+ years` = sum(`Deaths - HIV/AIDS - Sex: Both - Age: 70+ years (Number)`))  \n\nyear_sums_50 <- HIV_GBD %>% group_by(Year) %>% \n  summarize(`50-69 years` = sum(`Deaths - HIV/AIDS - Sex: Both - Age: 50-69 years (Number)`))  \n\nyear_sums_15 <- HIV_GBD %>% group_by(Year) %>% summarize(`15-49 years`  = sum(`Deaths - HIV/AIDS - Sex: Both - Age: 15-49 years (Number)`))  \n\nyear_sums_5 <- HIV_GBD %>% group_by(Year) %>% \n  summarize(`5-14 years` = sum(`Deaths - HIV/AIDS - Sex: Both - Age: 5-14 years (Number)`)) \n\nyear_sums_0 <- HIV_GBD %>% group_by(Year) %>% \n  summarize(`Under 5 years` = sum(`Deaths - HIV/AIDS - Sex: Both - Age: Under 5 (Number)`)) \n\nLet’s join the datasets and check to see how things are looking.\n\nyear_sums <-list(year_sums_70, year_sums_50, year_sums_15, year_sums_5, year_sums_0)\nyear_sums <- year_sums %>% reduce(full_join)\n\nJoining with `by = join_by(Year)`\nJoining with `by = join_by(Year)`\nJoining with `by = join_by(Year)`\nJoining with `by = join_by(Year)`\n\nglimpse(year_sums)\n\nRows: 30\nColumns: 6\n$ Year            <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, …\n$ `70+ years`     <dbl> 20399, 26573, 33797, 41998, 51362, 61170, 71366, 80974…\n$ `50-69 years`   <dbl> 206148, 265170, 334139, 414419, 505039, 596589, 676115…\n$ `15-49 years`   <dbl> 1169847, 1507786, 1901048, 2355302, 2857896, 3371592, …\n$ `5-14 years`    <dbl> 14380, 19461, 26079, 35140, 46940, 60284, 75037, 90767…\n$ `Under 5 years` <dbl> 371472, 459127, 553263, 651461, 747455, 839116, 919408…\n\n\nNice! Let’s make things a bit easier to plot by pivoting the data into long format.\n\nsums_long <- year_sums %>% \n  pivot_longer(2:6, names_to = \"Age\", values_to = \"Deaths\")\n\nWe’ll make age group a factor…\n\nsums_long <- sums_long %>%\n  mutate(Age = as.factor(Age), \n  Age = factor(\n      Age,\n      level = c(\"Under 5 years\", \"5-14 years\",\"15-49 years\", \"50-69 years\", \"70+ years\")))\n\nNow let’s plot it\n\nsums_long %>% ggplot(aes(x= Year, y = Deaths, color=Age, fill = Age))  +\n  geom_area() + labs(title = \"Deaths from HIV/AIDS , by age, World, 1990 to 2019\") + \n  theme_bw()\n\n\n\n\nWait! Something is not looking right with the data… our counts are significantly higher than those shown in the original plot. Let’s see if we find out why… Let’s load ‘naniar’ to see if there is anything unexpected about the data.\n\nlibrary(naniar)\nvis_miss(HIV_GBD)\n\n\n\n\nIt looks like the column ‘Entity’ contains data for both countries and continents! Let’s try to correct this by dropping observations missing a country code.\n\nHIV_GBD <- HIV_GBD %>% drop_na(Code)\n\n\nHIV_GBD %>% group_by(Year) %>%\n  slice_max(`Deaths - HIV/AIDS - Sex: Both - Age: 70+ years (Number)`)\n\n# A tibble: 30 × 8\n# Groups:   Year [30]\n   Entity Code      Year Deaths - HIV/AIDS - S…¹ Death…² Death…³ Death…⁴ Death…⁵\n   <chr>  <chr>    <dbl>                   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 World  OWID_WRL  1990                    3954   38533  217774    2712   73413\n 2 World  OWID_WRL  1991                    5152   49785  281693    3706   90819\n 3 World  OWID_WRL  1992                    6567   63068  356532    5013  109445\n 4 World  OWID_WRL  1993                    8175   78513  442911    6782  128770\n 5 World  OWID_WRL  1994                    9998   95881  538488    9084  147553\n 6 World  OWID_WRL  1995                   11907  113569  636910   11721  165293\n 7 World  OWID_WRL  1996                   13880  129592  723923   14650  180613\n 8 World  OWID_WRL  1997                   15741  144713  803647   17796  193410\n 9 World  OWID_WRL  1998                   17651  161922  898187   21356  205780\n10 World  OWID_WRL  1999                   19473  179766 1001519   25126  215227\n# … with 20 more rows, and abbreviated variable names\n#   ¹​`Deaths - HIV/AIDS - Sex: Both - Age: 70+ years (Number)`,\n#   ²​`Deaths - HIV/AIDS - Sex: Both - Age: 50-69 years (Number)`,\n#   ³​`Deaths - HIV/AIDS - Sex: Both - Age: 15-49 years (Number)`,\n#   ⁴​`Deaths - HIV/AIDS - Sex: Both - Age: 5-14 years (Number)`,\n#   ⁵​`Deaths - HIV/AIDS - Sex: Both - Age: Under 5 (Number)`\n\n\nThat explains it! Things were getting counted twice. Let’s making new dataframe where containing only observations for the ‘World’.\n\nworld <- HIV_GBD %>% \n  filter(grepl(\"OWID_WRL\", Code))\n\nRe-running the previous code…\n\nworld70 <- world %>% group_by(Year) %>% \n  summarize(`70+ years` = sum(`Deaths - HIV/AIDS - Sex: Both - Age: 70+ years (Number)`))  \n\nworld50 <- world %>% group_by(Year) %>% \n  summarize(`50-69 years` = sum(`Deaths - HIV/AIDS - Sex: Both - Age: 50-69 years (Number)`))  \n\nworld15 <- world %>% group_by(Year) %>% \n  summarize(`15-49 years`  = sum(`Deaths - HIV/AIDS - Sex: Both - Age: 15-49 years (Number)`))  \n\nworld5 <- world %>% group_by(Year) %>% \n  summarize(`5-14 years` = sum(`Deaths - HIV/AIDS - Sex: Both - Age: 5-14 years (Number)`)) \n\nworld0 <- world %>% group_by(Year) %>% \n  summarize(`Under 5 years` = sum(`Deaths - HIV/AIDS - Sex: Both - Age: Under 5 (Number)`)) \n\nworld <- list(world70, world50, world15, world5, world0)\nworld <- world %>% reduce(full_join)\n\nJoining with `by = join_by(Year)`\nJoining with `by = join_by(Year)`\nJoining with `by = join_by(Year)`\nJoining with `by = join_by(Year)`\n\nworld_long <- world %>% \n  pivot_longer(2:6, names_to = \"Age\", values_to = \"Deaths\") %>% \n  mutate(Age = as.factor(Age), \n  Age = factor(\n      Age,\n      level = c(\"Under 5 years\", \"5-14 years\",\"15-49 years\", \"50-69 years\", \"70+ years\")))\n\n\nworld_long %>% ggplot(aes(x= Year, y = Deaths, color=Age, fill = Age)) + \n  geom_area() + labs(title = \"Deaths from HIV/AIDS , by age, World, 1990 to 2019\")\n\n\n\n\nLet’s try to better match the original plot. We’ll first reverse the order of the age groups\n\nworld_long <- world_long %>% \n  mutate(Age = fct_rev(Age))\n\nThen we’ll load some useful packages. We’ll load ‘scales’ so that we can add ‘Million’ to the plot and RColorBrewer.\n\nlibrary(scales)\nlibrary(RColorBrewer)\nlibrary(extrafont)\n\n\nplot <- world_long %>% ggplot(aes(x= Year, y = Deaths, color = Age, fill = Age)) +\n  geom_area(alpha = 0.7) + \n  labs(title = \"Deaths from HIV/AIDS , by age, World, 1990 to 2019\") + \n  theme_bw() + scale_fill_brewer(palette = \"Oranges\",\ndirection = -1) + scale_color_brewer(palette = \"Oranges\", direction = -1) +\n  theme(plot.title = element_text(family = \"serif\")) +\n  theme(axis.title.x=element_blank(), axis.title.y=\n          element_blank(), axis.ticks.y = element_blank()) +\n  scale_x_continuous(breaks=c(1990, 1995, 2000, 2005, 2010, 2015, 2019)) + \n  scale_y_continuous(breaks=c(2e5, 4e5, 6e5, 8e5, 1e6, 1.2e6, 1.4e6, 1.6e6, 1.8e6), \n labels = c(\"200,000\",\"400,000\",\"600,000\",\"800,000\" , \"1 Million\", \"1.2 Million\", \n            \"1.4 Million\", \"1.6 Million\", \"1.8 Million\")) +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_line(\n    linetype = \"dashed\"),\npanel.border = element_blank(), axis.line.x = element_line(color = \"gray\"))\n\nplot\n\n\n\n\nNot exactly perfect, but we’re getting pretty close!\nAbout the code– alpha is used to the change transparency; I reversed the order of colors in the scale_x_brewer by using direction = -1; I manually specified my breaks for both axes, and add a label to the y axis. I removed major grid-lines and the border around the plot using theme and element blank, and changed the line type of the minor grid-lines, made the x axis line gray.\nSome websites I referred to were:\nggplot2 Reference and Examples (Part 2) - Colours\nStatistics Globe\nLet’s try to directly label the age groups to the plot to better match the original. First, we’ll need to subset the data to just the last observation for x.\n\nw_19 <- world_long %>% filter(Year == 2019)\n\nLet’s also make a new vector containing the age groups.\n\nag <- factor(c(\"Under 5 years\", \"5-14 years\",\"15-49 years\", \"50-69 years\", \"70+ years\"))\nag<- factor(ag, level = c(\"Under 5 years\", \"5-14 years\",\"15-49 years\", \"50-69 years\", \"70+ years\"), fct_rev(ag))\n\nLet’s see how this works…\n\nplot + geom_text(data = w_19, aes(x = 2021.5, y = c(8.7e5, 7.5e5, 4e5, 8.5e4, 100), label = Age),\n    alpha= 2) + theme(legend.position = \"none\") +\n      scale_y_continuous(breaks=c(2e5, 4e5, 6e5, 8e5, 1e6, 1.2e6, 1.4e6, 1.6e6, 1.8e6), \n labels = c(\"200,000\",\"400,000\",\"600,000\",\"800,000\" , \"1 Million\", \"1.2 Million\", \n            \"1.4 Million\", \"1.6 Million\", \"1.8 Million\"),\n sec.axis = sec_axis(~ ., breaks = c(8.7e5, 7.5e5, 4e5, 8.5e4, 100, labels = ag)))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n\n\n\n\n\nNot how I hoped, but I think that I’m on the right track… Some things that I definitely want to work on are making the ‘Under 5 Years’ label more visible and adding direct labels onto the plot.\nSomething to note about this is that when I called scale_y_continuous, it overwrote the previous y scale with labels that I had specified. To get around this, I added that part again and it worked well. Notice the warning message."
  },
  {
    "objectID": "dataanalysis_exercise.html",
    "href": "dataanalysis_exercise.html",
    "title": "Data Analysis Exercise",
    "section": "",
    "text": "This dataset describes drug poisoning deaths in the United States from 1999 - 2015 by demographic factors, including age group, sex, and a simple race/ethnicity variable (NH White, NH Black, Hispanic). This dataset includes all drug poisoning deaths– intentional(suicide and homicide), unintentional, and those with undetermined intent. While this dataset includes some data at the state-level, further investigation into trends of drug poisoning deaths at the state level is limited due to the fact that the data have been aggregated.\nLet’s load the packages we’ll be using in this analysis.\nLoading the dataset…\nLet’s take a look at the data.\nLet’s remove observations at the state-level by filtering for only observations where ‘state’ is the “United States” and remove columns that we won’t be using in the analysis.\nNext, let’s reclass some of our variables. We will also reorder the dataset so that Year is sorted chronologically, then by age group and sex.\nNext, let’s remove observations where rates have been aggregated and remove the columns with NA’s,\nTo make some of these variable easier to work with, let’s rename them.\nLet’s see if we can extract some data from other minorities….\nBefore starting data visualization, let’s reorder the race/ethnicity variable by decreasing crude death rate so that our legend for our plots is easier to interpret.\nLet’s clear the environment and start fresh by loading up the RDS file we just saved!\nSummary Table\nData Visualization and next steps…\nMy idea with this dataset is to explore trends in drug poisoning deaths across a number of demographic factors. Variables of interest are age group (especially ages 25-44), sex, and race/ethnicity."
  },
  {
    "objectID": "coding_exercise.html#continued-data-visualization-and-analysis",
    "href": "coding_exercise.html#continued-data-visualization-and-analysis",
    "title": "R Coding Exercise",
    "section": "Continued Data Visualization and Analysis",
    "text": "Continued Data Visualization and Analysis\n\nCountry Contributions to Continental GDP\n\n# How Much Does Each Country Contribute to Continent's Overall GDP?\n## Setting Up Initial Data\nregion_and_gdp <- africadata %>% filter(year == 1983) %>% group_by(region, gdp) %>% \n  select(country, region, gdp)\n## Creating a New Variable for Continent's GDP\nregion_and_gdp$total_gdp <- sum(region_and_gdp$gdp, na.rm = TRUE)\n# Percentage Contributed to Each \nregion_and_gdp <- region_and_gdp %>%\n  mutate(percentage = gdp/total_gdp * 100)\n\n# Graphing African Countries' Contributions to Continent's GDP\nggplot(region_and_gdp, aes(x = percentage, y = country, group = region, fill = region)) + geom_col() + labs(x = \"Percentage Contributed to Continent's GDP\", y = \"Nation\", title = \"Each Nation's Contribution to Continent's GDP in 1983\")\n\nWarning: Removed 7 rows containing missing values (`position_stack()`).\n\n\n\n\n\n\n\nLooking at What Factors Affect Population in Asia\n\nlibrary(broom)\n\nWarning: package 'broom' was built under R version 4.2.2\n\n# Creating a Model\npopulation_factors_model <- lm(population ~ fertility + life_expectancy + infant_mortality, data = gapminder %>% filter(continent == \"Asia\"))\n\n# Evaluating Model\npop_factors_model_table <- tidy(summary(population_factors_model))\n\nAccording to this model, fertility (p < 0.001) and life expectancy (p < 0.001) appear to significantly impact population in Asia since the null hypothesis that they do not is rejected. However, the null hypothesis that infant mortality does not affect population, in contrast, isn’t rejected."
  },
  {
    "objectID": "coding_exercise.html#fertility-over-time-in-europe",
    "href": "coding_exercise.html#fertility-over-time-in-europe",
    "title": "R Coding Exercise",
    "section": "Fertility Over Time in Europe",
    "text": "Fertility Over Time in Europe\n\n# Investigating Fertility Across Time\nggplot(gapminder %>% filter(continent == \"Europe\"), aes(x = year, y = fertility, group = region, color = region)) + geom_point() + labs(x = \"Year\", y = \"Fertility Rate\", title = \"Fertility Over Time in Europe\")\n\nWarning: Removed 39 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "coding_exercise.html#tracking-australias-gdp-over-time",
    "href": "coding_exercise.html#tracking-australias-gdp-over-time",
    "title": "R Coding Exercise",
    "section": "Tracking Australia’s GDP Over Time",
    "text": "Tracking Australia’s GDP Over Time\n\n# Investigating Australia's GDP Across Time\nggplot(gapminder %>% filter(country == \"Australia\"), aes(x = year, y = gdp, color = year)) + geom_point() + geom_line() + labs(x = \"Year\", y = \"GDP\", title = \"GDP Over Time for Australia\")\n\nWarning: Removed 5 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 5 rows containing missing values (`geom_line()`)."
  },
  {
    "objectID": "dataanalysis_exercise.html#this-section-added-by-connor-ross",
    "href": "dataanalysis_exercise.html#this-section-added-by-connor-ross",
    "title": "Data Analysis Exercise",
    "section": "This section added by CONNOR ROSS",
    "text": "This section added by CONNOR ROSS\nHi Hayley! Thanks for the Intro. This is a really meaningful and cool topic.\n\n# You know I got to have some tidyverseeeee...\nlibrary(tidyverse)\n\n\n# Let's take a look at what we got...\nstr(df)\n\ntibble [1,088 × 7] (S3: tbl_df/tbl/data.frame)\n $ Year      : num [1:1088] 1999 1999 1999 1999 1999 ...\n $ Sex       : Factor w/ 3 levels \"Both Sexes\",\"Female\",..: 2 3 2 3 2 3 2 3 2 3 ...\n $ Age       : Factor w/ 9 levels \"Less than 15 years\",..: 1 1 2 2 3 3 4 4 5 5 ...\n $ race_eth  : Factor w/ 4 levels \"Non-Hispanic White\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ Deaths    : num [1:1088] 11 11 26 78 126 302 305 631 177 551 ...\n $ Population: num [1:1088] 4604949 4748293 2799428 2761491 2752017 ...\n $ crude_dr  : num [1:1088] 0.2 0.2 0.9 2.8 4.6 12.2 10.4 24.4 8.3 30.4 ...\n\nsummary(df)\n\n      Year              Sex                      Age     \n Min.   :1999   Both Sexes:  0   Less than 15 years:136  \n 1st Qu.:2003   Female    :544   15-24 years       :136  \n Median :2007   Male      :544   25-34 years       :136  \n Mean   :2007                    35-44 years       :136  \n 3rd Qu.:2011                    45-54 years       :136  \n Max.   :2015                    55-64 years       :136  \n                                 (Other)           :272  \n                    race_eth       Deaths          Population      \n Non-Hispanic White     :272   Min.   :   0.00   Min.   :  146555  \n Non-Hispanic Black     :272   1st Qu.:  21.75   1st Qu.: 1161401  \n Hispanic               :272   Median : 102.50   Median : 2585722  \n Non-Hispanic Other Race:272   Mean   : 522.58   Mean   : 4699098  \n                               3rd Qu.: 388.25   3rd Qu.: 6651233  \n                               Max.   :6874.00   Max.   :19270575  \n                                                                   \n    crude_dr     \n Min.   : 0.000  \n 1st Qu.: 2.300  \n Median : 4.600  \n Mean   : 8.045  \n 3rd Qu.:11.300  \n Max.   :53.500  \n                 \n\n# Sweet summary stats but I'm more of a visual person...\n\n## Aggregate Death Count by Sex\ndf %>%\n  ggplot(aes(x = factor(Sex), y = Deaths, fill = factor(Sex))) + \n  geom_bar(stat = \"identity\") +\n  labs(title = \"Deaths by Sex\", x = \"Sex (Male or Female)\",\n       y = \"Aggregate Deaths (All Age Groups from 1999 - 2015)\", fill = \"Sex\") +\n  theme_dark()\n\n\n\n## Aggregate Death Count by Race/Ethnicity\ndf %>%\n  ggplot(aes(x = factor(race_eth), y = Deaths, fill = factor(race_eth))) + \n  geom_bar(stat = \"identity\") +\n  labs(title = \"Drug Poison Deaths by Race/Ethnicity\", x = \"Race/Ethnicity\",\n       y = \"Aggregate Deaths (All Races/Ethnicities from 1999 - 2015)\",\n       fill = \"Race/Ethnicity\") +\n  theme_dark()\n\n\n\ndf %>%\n  ggplot(aes(x = factor(race_eth), y = log(Deaths), fill = factor(race_eth))) + \n  geom_bar(stat = \"identity\") +\n  labs(title = \"Log Drug Poison Deaths by Race/Ethnicity in the US\", \n       x = \"Race/Ethnicity\",\n       y = \"Log Deaths (All Races/Ethnicities from 1999 - 2015)\",\n       fill = \"Race/Ethnicity\") +\n  theme_dark()\n\nWarning: Removed 7 rows containing missing values (`geom_bar()`).\n\n\n\n\n## Aggregate Death Count by Age Group\ndf %>%\n  ggplot(aes(x = factor(Age), y = Deaths, fill = factor(Age))) + \n  geom_bar(stat = \"identity\") +\n  labs(title = \"Deaths by Age\", x = \"Age Group\",\n       y = \"Aggregate Deaths (from 1999 - 2015)\", fill = \"Age\") +\n  theme_dark()\n\n\n\ndf %>%\n  filter(Age == \"25-34 years\" | Age == \"35-44 years\") %>%\n  ggplot(aes(x = factor(Age), y = Deaths, fill = factor(Age))) + \n  geom_bar(stat = \"identity\") +\n  labs(title = \"Deaths by Age\", x = \"Age Group\",\n       y = \"Aggregate Deaths (from 1999 - 2015)\", fill = \"Age\") +\n  theme_dark()\n\n\n\n## CDR Trends by Age Group\ndf %>%\n  ggplot(aes(x = Year, y = crude_dr, color = Age)) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Drug Poison Death Rate Trends by Age Group in the US\", \n       x = \"Year of Death\", \n       y = \"Crude Death Rate (per 100,000)\") +\n  theme_dark()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n### CDR Trends by Sex\ndf %>%\n  ggplot(aes(x = Year, y = crude_dr, color = Sex)) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Drug Poison Death Rate Trends by Sex in the US\", \n       x = \"Year of Death\", \n       y = \"Crude Death Rate (per 100,000)\") +\n  theme_dark()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\ndf %>%\n  filter(Age == \"25-34 years\" | Age == \"35-44 years\") %>%\n  ggplot(aes(x = Year, y = crude_dr, color = Age)) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Drug Poison Death Rate Trends by Age Group in the US\", \n       x = \"Year of Death\", \n       y = \"Crude Death Rate (per 100,000)\") +\n  theme_dark()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "fluanalysis/code/exploration.html",
    "href": "fluanalysis/code/exploration.html",
    "title": "Exploration",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\n\n\nflu <- readRDS(here(\"fluanalysis/data/processed_data/flu.rds\"))\n\nLet’s take a look at some summary statistics for BodyTemp and Nausea\n\nsummary(flu$BodyTemp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  97.20   98.20   98.50   98.94   99.30  103.10 \n\nsummary(flu$Nausea)\n\n No Yes \n475 255 \n\n\nNext, let’s take a look at this distribution of BodyTemp.\n\nflu  %>% ggplot(aes(x = BodyTemp))  + geom_histogram(bins = 20)\n\n\n\n\nI’m also interested in the intensity variables… Let’s make a box plot of a couple of these with BodyTemp.\n\nflu %>% ggplot(aes(x= BodyTemp, y = Myalgia, color = Myalgia)) +\n  geom_boxplot() \n\n\n\nflu %>% ggplot(aes(x= BodyTemp, y = Weakness, color = Weakness)) +\n  geom_boxplot()\n\n\n\n\nMedian body temperature appears to increase with increasing intensity of myalgia/ weakness.\nLet’s look at this as a histogram for weakness.\n\nflu  %>% ggplot(aes(x = BodyTemp, fill = Weakness)) + \n  geom_histogram(bins = 20) \n\n\n\n\nWeakness by Nausea contingency table\n\ntable(flu$Weakness,flu$Nausea)\n\n          \n            No Yes\n  None      39  10\n  Mild     172  51\n  Moderate 210 128\n  Severe    54  66\n\n\nMyalgia by Nausea contingency table\n\ntable(flu$Myalgia,flu$Nausea)\n\n          \n            No Yes\n  None      63  16\n  Mild     159  54\n  Moderate 198 127\n  Severe    55  58\n\n\nCough Intensity by Nausea contingency table\n\ntable(flu$CoughIntensity,flu$Nausea)\n\n          \n            No Yes\n  None      30  17\n  Mild      99  55\n  Moderate 232 125\n  Severe   114  58\n\n\nNow let’s take visualize this.\n\nflu %>% ggplot(aes(x= Weakness, fill = CoughIntensity)) +\n  geom_histogram(stat=\"count\")\n\n\n\nflu %>% ggplot(aes(x= Weakness, fill = Myalgia)) +\n  geom_histogram(stat=\"count\")\n\n\n\nflu %>% ggplot(aes(x= Weakness, fill = Nausea)) +\n  geom_histogram(stat=\"count\")\n\n\n\n\nWeakness by Nausea contingency table\n\ntable(flu$Weakness,flu$Myalgia)\n\n          \n           None Mild Moderate Severe\n  None       22   22        5      0\n  Mild       37  120       62      4\n  Moderate   18   64      208     48\n  Severe      2    7       50     61"
  },
  {
    "objectID": "fluanalysis/code/wrangling.html",
    "href": "fluanalysis/code/wrangling.html",
    "title": "Wrangling",
    "section": "",
    "text": "Load packages\n\nlibrary(here)\nlibrary(tidyverse)\n\nLoad the data\n\nflu <- readRDS(here(\"fluanalysis/data/raw_data/SympAct_Any_Pos.Rda\"))\n\nLet’s take a look at the dataset using glimpse\n\nglimpse(flu)\n\nRows: 735\nColumns: 63\n$ DxName1           <fct> \"Influenza like illness - Clinical Dx\", \"Acute tonsi…\n$ DxName2           <fct> NA, \"Influenza like illness - Clinical Dx\", \"Acute p…\n$ DxName3           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Fever, unspecified\"…\n$ DxName4           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Other fatigue\", NA,…\n$ DxName5           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Headache\", NA, NA, …\n$ Unique.Visit      <chr> \"340_17632125\", \"340_17794836\", \"342_17737773\", \"342…\n$ ActivityLevel     <int> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ ActivityLevelF    <fct> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n$ RapidFluA         <fct> Presumptive Negative For Influenza A, NA, Presumptiv…\n$ RapidFluB         <fct> Presumptive Negative For Influenza B, NA, Presumptiv…\n$ PCRFluA           <fct> NA, NA, NA, NA, NA, NA,  Influenza A Not Detected, N…\n$ PCRFluB           <fct> NA, NA, NA, NA, NA, NA,  Influenza B Not Detected, N…\n$ TransScore1       <dbl> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore1F      <fct> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore2       <dbl> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore2F      <fct> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore3       <dbl> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore3F      <fct> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore4       <dbl> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ TransScore4F      <fct> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ ImpactScore       <int> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2      <int> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3      <int> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreF      <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2F     <fct> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3F     <fct> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreFD     <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ TotalSymp1        <dbl> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp1F       <fct> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp2        <dbl> 8, 10, 17, 16, 11, 14, 10, 11, 13, 10, 14, 19, 13, 1…\n$ TotalSymp3        <dbl> 8, 9, 16, 15, 11, 14, 10, 10, 12, 9, 13, 18, 12, 16,…\n\n\nNow that we have an idea of what the data looks like, let’s drop variables we won’t be using in our analysis using select and remove missing observations.\n\nflu <- flu %>%\n  select(-contains(c(\"Score\", \"Flu\")),\n         -starts_with(c(\"DxName\", \"Activity\", \"Total\", \"Unique.Visit\"))) %>%\n  drop_na()\n\nglimpse(flu)\n\nRows: 730\nColumns: 32\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n\n\n\nsaveRDS(flu, here(\"fluanalysis/data/processed_data/flu.rds\"))"
  },
  {
    "objectID": "wrangling.html",
    "href": "wrangling.html",
    "title": "Wrangling",
    "section": "",
    "text": "Load packages\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Hayley/Desktop/MADA2023/hayleyhemme-MADA-portfolio\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2\n──\n\n\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'tidyr' was built under R version 4.2.2\n\n\nWarning: package 'readr' was built under R version 4.2.2\n\n\nWarning: package 'purrr' was built under R version 4.2.2\n\n\nWarning: package 'dplyr' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\nWarning: package 'forcats' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nLoad the data\n\nflu <- readRDS(here(\"fluanalysis/data/raw_data/SympAct_Any_Pos.Rda\"))\n\nLet’s take a look at the dataset using glimpse\n\nglimpse(flu)\n\nRows: 735\nColumns: 63\n$ DxName1           <fct> \"Influenza like illness - Clinical Dx\", \"Acute tonsi…\n$ DxName2           <fct> NA, \"Influenza like illness - Clinical Dx\", \"Acute p…\n$ DxName3           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Fever, unspecified\"…\n$ DxName4           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Other fatigue\", NA,…\n$ DxName5           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Headache\", NA, NA, …\n$ Unique.Visit      <chr> \"340_17632125\", \"340_17794836\", \"342_17737773\", \"342…\n$ ActivityLevel     <int> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ ActivityLevelF    <fct> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n$ RapidFluA         <fct> Presumptive Negative For Influenza A, NA, Presumptiv…\n$ RapidFluB         <fct> Presumptive Negative For Influenza B, NA, Presumptiv…\n$ PCRFluA           <fct> NA, NA, NA, NA, NA, NA,  Influenza A Not Detected, N…\n$ PCRFluB           <fct> NA, NA, NA, NA, NA, NA,  Influenza B Not Detected, N…\n$ TransScore1       <dbl> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore1F      <fct> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore2       <dbl> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore2F      <fct> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore3       <dbl> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore3F      <fct> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore4       <dbl> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ TransScore4F      <fct> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ ImpactScore       <int> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2      <int> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3      <int> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreF      <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2F     <fct> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3F     <fct> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreFD     <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ TotalSymp1        <dbl> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp1F       <fct> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp2        <dbl> 8, 10, 17, 16, 11, 14, 10, 11, 13, 10, 14, 19, 13, 1…\n$ TotalSymp3        <dbl> 8, 9, 16, 15, 11, 14, 10, 10, 12, 9, 13, 18, 12, 16,…\n\n\nNow that we have an idea of what the data looks like, let’s drop variables we won’t be using in our analysis using select and remove missing observations.\n\nflu <- flu %>%\n  select(-contains(c(\"Score\", \"Flu\")),\n         -starts_with(c(\"DxName\", \"Activity\", \"Total\", \"Unique.Visit\"))) %>%\n  drop_na()\n\nglimpse(flu)\n\nRows: 730\nColumns: 32\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n\n\n\nsaveRDS(flu, here(\"fluanalysis/data/processed_data/flu.rds\"))"
  },
  {
    "objectID": "fluanalysis/code/fitting.html",
    "href": "fluanalysis/code/fitting.html",
    "title": "Model fitting",
    "section": "",
    "text": "library(here)\nlibrary(tidymodels)\nlibrary(performance)\nlibrary(tidyverse)\n\n\nflu <- readRDS(here(\"fluanalysis/data/processed_data/flu.rds\"))\n\nUnivariate model for\n\nlm_mod <- linear_reg() %>% \n  set_engine(\"lm\") %>% \n  fit(BodyTemp ~ Weakness, data = flu)\n\ntidy(lm_mod)\n\n# A tibble: 4 × 5\n  term             estimate std.error statistic p.value\n  <chr>               <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        98.6       0.170    580.   0      \n2 WeaknessMild        0.256     0.188      1.37 0.172  \n3 WeaknessModerate    0.317     0.182      1.74 0.0816 \n4 WeaknessSevere      0.619     0.202      3.07 0.00221\n\nglance(lm_mod)\n\n# A tibble: 1 × 12\n  r.squ…¹ adj.r…² sigma stati…³ p.value    df logLik   AIC   BIC devia…⁴ df.re…⁵\n    <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>   <int>\n1  0.0159  0.0119  1.19    3.92 0.00857     3 -1160. 2331. 2354.   1027.     726\n# … with 1 more variable: nobs <int>, and abbreviated variable names\n#   ¹​r.squared, ²​adj.r.squared, ³​statistic, ⁴​deviance, ⁵​df.residual\n\n\nMultivariate model (full)\n\nlm_full <- linear_reg() %>%\n  set_engine(\"lm\") %>% \n  fit(BodyTemp ~ . ,data = flu)\n\ntidy(lm_full)\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic   p.value\n   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)           97.9       0.304   322.     0        \n 2 SwollenLymphNodesYes  -0.165     0.0920   -1.80   0.0727   \n 3 ChestCongestionYes     0.0873    0.0975    0.895  0.371    \n 4 ChillsSweatsYes        0.201     0.127     1.58   0.114    \n 5 NasalCongestionYes    -0.216     0.114    -1.90   0.0584   \n 6 CoughYNYes             0.314     0.241     1.30   0.193    \n 7 SneezeYes             -0.362     0.0983   -3.68   0.000249 \n 8 FatigueYes             0.265     0.161     1.65   0.0996   \n 9 SubjectiveFeverYes     0.437     0.103     4.22   0.0000271\n10 HeadacheYes            0.0115    0.125     0.0913 0.927    \n# … with 28 more rows\n\nglance(lm_full)\n\n# A tibble: 1 × 12\n  r.squ…¹ adj.r…² sigma stati…³ p.value    df logLik   AIC   BIC devia…⁴ df.re…⁵\n    <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>   <int>\n1   0.129  0.0860  1.14    3.02 4.20e-8    34 -1116. 2304. 2469.    909.     695\n# … with 1 more variable: nobs <int>, and abbreviated variable names\n#   ¹​r.squared, ²​adj.r.squared, ³​statistic, ⁴​deviance, ⁵​df.residual\n\n\nComparing model performance for univariate vs multivariate linear model.\n\ncompare_performance(lm_mod, lm_full)\n\n# Comparison of Model Performance Indices\n\nName    | Model |  AIC (weights) | AICc (weights) |  BIC (weights) |    R2 | R2 (adj.) |  RMSE | Sigma\n------------------------------------------------------------------------------------------------------\nlm_mod  |   _lm | 2330.7 (<.001) | 2330.7 (<.001) | 2353.6 (>.999) | 0.016 |     0.012 | 1.186 | 1.189\nlm_full |   _lm | 2303.8 (>.999) | 2307.7 (>.999) | 2469.2 (<.001) | 0.129 |     0.086 | 1.116 | 1.144\n\n\nThe full model appears to be a better fit than univariate model with a lower AIC of 2307.8 and higher R2(adj.) of 0.086.\nLet’s try to make some predictions for the full model. We’ll use the mean body temperature we found earlier\n\nnew_points <- expand.grid(BodyTemp = 98.94, \n                          Weakness = c(\"None\", \"Mild\", \"Moderate\", \"Severe\"))\n\n##Mean prediction\nmean_pred <- predict(lm_mod, new_data = new_points)\nmean_pred\n\n# A tibble: 4 × 1\n  .pred\n  <dbl>\n1  98.6\n2  98.9\n3  98.9\n4  99.2\n\n#Confidence intervals\nconf_int_pred <- predict(lm_mod, \n                         new_data = new_points, \n                         type = \"conf_int\")\nconf_int_pred\n\n# A tibble: 4 × 2\n  .pred_lower .pred_upper\n        <dbl>       <dbl>\n1        98.3        98.9\n2        98.7        99.0\n3        98.8        99.1\n4        99.0        99.4\n\n\n\nplot_data <- \n  new_points %>% \n  bind_cols(mean_pred) %>% \n  bind_cols(conf_int_pred)\n\nggplot(plot_data, aes(x = Weakness)) + \n  geom_point(aes(y = .pred)) + \n  geom_errorbar(aes(ymin = .pred_lower, \n                    ymax = .pred_upper),\n                width = .2) + \n  labs(y = \"Body Temperature (F)\")\n\n\n\n\nFitting univariate model - Logistic regression\n\nlog_mod <- logistic_reg() %>% \n  set_engine(\"glm\") %>% \n  fit(Nausea ~ Myalgia, data = flu)\n\ntidy(log_mod)\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic     p.value\n  <chr>              <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)       -1.37      0.280    -4.90  0.000000980\n2 MyalgiaMild        0.291     0.321     0.905 0.366      \n3 MyalgiaModerate    0.926     0.302     3.07  0.00217    \n4 MyalgiaSevere      1.42      0.337     4.22  0.0000244  \n\n#Results\nglance(log_mod)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1          945.     729  -456.  920.  939.     912.         726   730\n\n\nFitting the full model - logistic regression\n\nlog_full <- logistic_reg() %>% \n  set_engine(\"glm\") %>% \n  fit(Nausea ~ ., data = flu)\n\ntidy(log_full)\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)             0.223     7.83     0.0285  0.977 \n 2 SwollenLymphNodesYes   -0.251     0.196   -1.28    0.200 \n 3 ChestCongestionYes      0.276     0.213    1.30    0.195 \n 4 ChillsSweatsYes         0.274     0.288    0.952   0.341 \n 5 NasalCongestionYes      0.426     0.255    1.67    0.0944\n 6 CoughYNYes             -0.140     0.519   -0.271   0.787 \n 7 SneezeYes               0.177     0.210    0.840   0.401 \n 8 FatigueYes              0.229     0.372    0.616   0.538 \n 9 SubjectiveFeverYes      0.278     0.225    1.23    0.218 \n10 HeadacheYes             0.331     0.285    1.16    0.245 \n# … with 28 more rows\n\nglance(log_full)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1          945.     729  -376.  821.  982.     751.         695   730\n\n\nComparing model performance for univariate vs multiple logistic regression model.\n\ncompare_performance(log_mod, log_full)\n\n# Comparison of Model Performance Indices\n\nName     | Model | AIC (weights) | AICc (weights) | BIC (weights) | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n----------------------------------------------------------------------------------------------------------------------------------------------\nlog_mod  |  _glm | 920.3 (<.001) |  920.3 (<.001) | 938.7 (>.999) |     0.044 | 0.466 | 1.121 |    0.625 |  -110.929 |           0.006 | 0.565\nlog_full |  _glm | 821.5 (>.999) |  825.1 (>.999) | 982.2 (<.001) |     0.247 | 0.414 | 1.040 |    0.515 |      -Inf |           0.002 | 0.658\n\n\nThe full model appears to be a better fit than the univariate model, with an lower AIC of 821.5."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html",
    "href": "fluanalysis/code/modeleval.html",
    "title": "Model Evaluation",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\nflu <- readRDS(here(\"fluanalysis/data/processed_data/flu.rds\"))\n\n\n# setting the seed \nset.seed(222)\n# Put 3/4 of the data into the training set \ndata_split <- initial_split(flu, prop = 3/4)\n\n# Create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n\n\nn_flu <- \n  recipe(Nausea ~ ., data = train_data) \n\nSetting logistic regression engine\n\nlr_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nCreating workflow function using logistic regression model and training data\n\nflu_wflow <- \n  workflow() %>% \n  add_model(lr_mod) %>% \n  add_recipe(n_flu)\n\nCreating function that can be used to prepare the recipe and train the model\n\nflu_fit <- \n  flu_wflow %>% \n  fit(data = train_data)\n\nExtracting the model objects from the workflow\n\nflu_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)             1.63      9.40      0.173  0.862 \n 2 SwollenLymphNodesYes   -0.241     0.232    -1.04   0.298 \n 3 ChestCongestionYes      0.219     0.257     0.853  0.394 \n 4 ChillsSweatsYes         0.115     0.332     0.346  0.729 \n 5 NasalCongestionYes      0.560     0.311     1.80   0.0713\n 6 CoughYNYes             -0.705     0.611    -1.15   0.249 \n 7 SneezeYes               0.117     0.248     0.473  0.636 \n 8 FatigueYes              0.177     0.438     0.403  0.687 \n 9 SubjectiveFeverYes      0.229     0.264     0.868  0.385 \n10 HeadacheYes             0.435     0.352     1.24   0.216 \n# … with 28 more rows\n\n\nUsiing trained workflow to make predictions on testing data\n\npredict(flu_fit, test_data)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 No         \n 6 Yes        \n 7 Yes        \n 8 No         \n 9 No         \n10 Yes        \n# … with 173 more rows\n\nflu_aug <- \n  augment(flu_fit, test_data)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n# The data look like: \nflu_aug %>%\n  select(Nausea, .pred_No, .pred_Yes)\n\n# A tibble: 183 × 3\n   Nausea .pred_No .pred_Yes\n   <fct>     <dbl>     <dbl>\n 1 No        0.962    0.0377\n 2 Yes       0.717    0.283 \n 3 No        0.680    0.320 \n 4 Yes       0.558    0.442 \n 5 No        0.830    0.170 \n 6 Yes       0.188    0.812 \n 7 Yes       0.254    0.746 \n 8 No        0.725    0.275 \n 9 No        0.720    0.280 \n10 Yes       0.281    0.719 \n# … with 173 more rows\n\n\nPlotting ROC_AUC\n\nflu_aug %>% \n  roc_curve(truth = Nausea, .pred_No) %>% \n  autoplot()\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\nℹ The deprecated feature was likely used in the yardstick package.\n  Please report the issue at <https://github.com/tidymodels/yardstick/issues>.\n\n\n\n\nflu_aug %>% \n  roc_auc(truth = Nausea, .pred_No) \n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.724\n\n\nAlternative model\n\nflu_r <- \n  recipe(Nausea ~ BodyTemp, data = train_data) \n\nCreating workflow function using lr model function and training data\n\nflu_wflow_r <- \n  workflow() %>% \n  add_model(lr_mod) %>% \n  add_recipe(flu_r)\n\nCreating function that can be used to prepare the recipe and train the model\n\nflu_fit_r <- \n  flu_wflow_r %>% \n  fit(data = train_data)\n\nExtracting the model objects from the workflow\n\nflu_fit_r %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)  -5.85      7.27      -0.804   0.421\n2 BodyTemp      0.0524    0.0734     0.714   0.475\n\n\nUsing trained workflow to make predictions on testing data\n\npredict(flu_fit_r, test_data)\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 No         \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 No         \n# … with 173 more rows\n\nflu_aug_r <- \n  augment(flu_fit_r, test_data)\n\n# The data look like: \nflu_aug_r %>%\n  select(Nausea, .pred_No, .pred_Yes)\n\n# A tibble: 183 × 3\n   Nausea .pred_No .pred_Yes\n   <fct>     <dbl>     <dbl>\n 1 No        0.666     0.334\n 2 Yes       0.660     0.340\n 3 No        0.615     0.385\n 4 Yes       0.667     0.333\n 5 No        0.672     0.328\n 6 Yes       0.672     0.328\n 7 Yes       0.646     0.354\n 8 No        0.635     0.365\n 9 No        0.660     0.340\n10 Yes       0.644     0.356\n# … with 173 more rows\n\n\nPlotting ROC_AUC\n\nflu_aug_r %>% \n  roc_curve(truth = Nausea, .pred_No) %>% \n  autoplot()\n\n\n\nflu_aug_r %>% \n  roc_auc(truth = Nausea, .pred_No) \n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.537\n\n\nThe model using only body temperature as a predictor performed much more poorly than the full model!"
  }
]